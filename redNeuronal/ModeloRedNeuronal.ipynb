{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYQGA19Snude"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "class ModeloRedNeuronal:\n",
        "    def __init__(self, ruta_datos='DatasetCafeteriaNormalizado.csv'):\n",
        "        self.df = pd.read_csv(ruta_datos, delimiter=';')\n",
        "        self.caracteristicas = ['vecindario', 'genero', 'producto', 'grupo_producto',\n",
        "                         'tipo_producto', 'unidad_medida', 'cantidad',\n",
        "                         'monto_linea_articulo', 'etiqueta']\n",
        "        self.df = self.df[self.caracteristicas]\n",
        "        self.x_datos = self.df.drop('etiqueta', axis=1)\n",
        "        self.y_datos = self.df['etiqueta']\n",
        "        self.x_entrenamiento, self.x_prueba, self.y_entrenamiento, self.y_prueba = train_test_split(self.x_datos, self.y_datos, test_size=0.3)\n",
        "        self.rn_modelo = MLPClassifier(hidden_layer_sizes=(9, 1, 5), activation='relu', solver='sgd', max_iter=100,verbose=True)\n",
        "\n",
        "    def entrenar_modelo(self):\n",
        "        self.rn_modelo.fit(self.x_entrenamiento, self.y_entrenamiento)\n",
        "\n",
        "    def evaluar_modelo(self):\n",
        "        y_prediccion = self.rn_modelo.predict(self.x_prueba)\n",
        "        exactitud_prueba = accuracy_score(self.y_prueba, y_prediccion)\n",
        "        print('Exactitud en la prueba:', exactitud_prueba)\n",
        "\n",
        "    def puntuaciones_cruzadas(self, cv=5):\n",
        "        puntuaciones = cross_val_score(self.rn_modelo, self.x_entrenamiento, self.y_entrenamiento, cv=cv)\n",
        "        return puntuaciones\n",
        "\n",
        "    def guardar_modelo(self, nombre_archivo='modelventas.sav'):\n",
        "        pickle.dump(self.rn_modelo, open(nombre_archivo, 'wb'))\n",
        "        print('Modelo guardado exitosamente.')\n",
        "\n",
        "    def cargar_y_predecir(self, datos_entrada, nombre_modelo='modelventas.sav'):\n",
        "        modelo_cargado = pickle.load(open(nombre_modelo, 'rb'))\n",
        "        prediccion = modelo_cargado.predict([datos_entrada])\n",
        "        return prediccion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Crear una instancia de la clase\n",
        "    modelo_red_neuronal = ModeloRedNeuronal()\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    modelo_red_neuronal.entrenar_modelo()\n",
        "\n",
        "    # Evaluar el modelo\n",
        "    modelo_red_neuronal.evaluar_modelo()\n",
        "\n",
        "    # Guardar el modelo\n",
        "    modelo_red_neuronal.guardar_modelo()\n",
        "\n",
        "    # Cargar el modelo y hacer una predicción de ejemplo\n",
        "    datos_entrada_ejemplo = [3, 3, 4, 1, 23, 8, 2, 6.20]\n",
        "    prediccion_ejemplo = modelo_red_neuronal.cargar_y_predecir(datos_entrada_ejemplo)\n",
        "    print('Predicción:', prediccion_ejemplo)\n"
      ],
      "metadata": {
        "id": "GuhE7y82nzOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74420b3-5c42-4a71-8b78-d80b9999d89b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.38770719\n",
            "Iteration 2, loss = 1.26379588\n",
            "Iteration 3, loss = 1.20859284\n",
            "Iteration 4, loss = 1.17082798\n",
            "Iteration 5, loss = 1.14362552\n",
            "Iteration 6, loss = 1.12263311\n",
            "Iteration 7, loss = 1.10712407\n",
            "Iteration 8, loss = 1.09301631\n",
            "Iteration 9, loss = 1.08207769\n",
            "Iteration 10, loss = 1.07257698\n",
            "Iteration 11, loss = 1.06528932\n",
            "Iteration 12, loss = 1.05980848\n",
            "Iteration 13, loss = 1.05481691\n",
            "Iteration 14, loss = 1.05050691\n",
            "Iteration 15, loss = 1.04665505\n",
            "Iteration 16, loss = 1.04305329\n",
            "Iteration 17, loss = 1.04002254\n",
            "Iteration 18, loss = 1.03722167\n",
            "Iteration 19, loss = 1.03429060\n",
            "Iteration 20, loss = 1.03184531\n",
            "Iteration 21, loss = 1.02963255\n",
            "Iteration 22, loss = 1.02718550\n",
            "Iteration 23, loss = 1.02467852\n",
            "Iteration 24, loss = 1.01264554\n",
            "Iteration 25, loss = 0.98477726\n",
            "Iteration 26, loss = 0.96353306\n",
            "Iteration 27, loss = 0.94259218\n",
            "Iteration 28, loss = 0.90957775\n",
            "Iteration 29, loss = 0.88451338\n",
            "Iteration 30, loss = 0.86646803\n",
            "Iteration 31, loss = 0.85506834\n",
            "Iteration 32, loss = 0.84691668\n",
            "Iteration 33, loss = 0.84110863\n",
            "Iteration 34, loss = 0.83591850\n",
            "Iteration 35, loss = 0.83123497\n",
            "Iteration 36, loss = 0.82677135\n",
            "Iteration 37, loss = 0.82285993\n",
            "Iteration 38, loss = 0.81908274\n",
            "Iteration 39, loss = 0.81510375\n",
            "Iteration 40, loss = 0.81175893\n",
            "Iteration 41, loss = 0.80758325\n",
            "Iteration 42, loss = 0.79252074\n",
            "Iteration 43, loss = 0.77942373\n",
            "Iteration 44, loss = 0.76641699\n",
            "Iteration 45, loss = 0.75306424\n",
            "Iteration 46, loss = 0.73833682\n",
            "Iteration 47, loss = 0.72608563\n",
            "Iteration 48, loss = 0.71634360\n",
            "Iteration 49, loss = 0.70925535\n",
            "Iteration 50, loss = 0.70327092\n",
            "Iteration 51, loss = 0.69818033\n",
            "Iteration 52, loss = 0.69336285\n",
            "Iteration 53, loss = 0.68956240\n",
            "Iteration 54, loss = 0.68242996\n",
            "Iteration 55, loss = 0.67388332\n",
            "Iteration 56, loss = 0.66505614\n",
            "Iteration 57, loss = 0.65853577\n",
            "Iteration 58, loss = 0.65178142\n",
            "Iteration 59, loss = 0.64616278\n",
            "Iteration 60, loss = 0.64132574\n",
            "Iteration 61, loss = 0.63539769\n",
            "Iteration 62, loss = 0.62934803\n",
            "Iteration 63, loss = 0.62451974\n",
            "Iteration 64, loss = 0.61956178\n",
            "Iteration 65, loss = 0.61519313\n",
            "Iteration 66, loss = 0.61027560\n",
            "Iteration 67, loss = 0.60609503\n",
            "Iteration 68, loss = 0.60256464\n",
            "Iteration 69, loss = 0.59956465\n",
            "Iteration 70, loss = 0.59410698\n",
            "Iteration 71, loss = 0.59082987\n",
            "Iteration 72, loss = 0.58666872\n",
            "Iteration 73, loss = 0.58463154\n",
            "Iteration 74, loss = 0.57895564\n",
            "Iteration 75, loss = 0.57279831\n",
            "Iteration 76, loss = 0.56631431\n",
            "Iteration 77, loss = 0.56096935\n",
            "Iteration 78, loss = 0.55575625\n",
            "Iteration 79, loss = 0.54983307\n",
            "Iteration 80, loss = 0.54622584\n",
            "Iteration 81, loss = 0.54054777\n",
            "Iteration 82, loss = 0.53266013\n",
            "Iteration 83, loss = 0.52602649\n",
            "Iteration 84, loss = 0.51839986\n",
            "Iteration 85, loss = 0.51026797\n",
            "Iteration 86, loss = 0.50737526\n",
            "Iteration 87, loss = 0.49595791\n",
            "Iteration 88, loss = 0.49596587\n",
            "Iteration 89, loss = 0.48930478\n",
            "Iteration 90, loss = 0.48188366\n",
            "Iteration 91, loss = 0.47207997\n",
            "Iteration 92, loss = 0.49495064\n",
            "Iteration 93, loss = 0.47408172\n",
            "Iteration 94, loss = 0.46066657\n",
            "Iteration 95, loss = 0.48358071\n",
            "Iteration 96, loss = 0.44597909\n",
            "Iteration 97, loss = 0.44937630\n",
            "Iteration 98, loss = 0.49532393\n",
            "Iteration 99, loss = 0.43313027\n",
            "Iteration 100, loss = 0.44720937\n",
            "Exactitud en la prueba: 0.7634556327784063\n",
            "Modelo guardado exitosamente.\n",
            "Predicción: [4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "data = pd.read_csv(\"DatasetCafeteriaNormalizado.csv\")\n",
        "\n",
        "train_data, test_val_data = train_test_split(data, test_size=0.3, random_state=42)\n",
        "val_data, test_data = train_test_split(test_val_data, test_size=0.5, random_state=42)\n",
        "train_data.to_csv(\"train.csv\", index=False)\n",
        "val_data.to_csv(\"validation.csv\", index=False)\n",
        "test_data.to_csv(\"test.csv\", index=False)"
      ],
      "metadata": {
        "id": "r3V9ll34SMEp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}